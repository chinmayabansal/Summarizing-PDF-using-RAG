{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f00a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai\n",
    "# pip install PyPDF2\n",
    "\n",
    "# pip install faiss-cpu\n",
    "# pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3702bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d095a7a-f6ba-4fa7-9fa6-d45ed6680c91",
   "metadata": {},
   "source": [
    "# Reading PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cd738f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = open(\"tesla.pdf\",'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a499d76-ce1f-470f-bbd5-f319cf2de13e",
   "metadata": {},
   "source": [
    "## Implementing RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c363003-b709-4687-a8a7-d65727d496ec",
   "metadata": {},
   "source": [
    "#### Creating chunk of each page (not using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0c5019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_text = []\n",
    "# for page_num in range(len(pdf_reader.pages)):\n",
    "#     page_text.append(pdf_reader.pages[page_num].extract_text().lower())\n",
    "# df = pd.DataFrame({\"page\":page_text})\n",
    "# df['page'] = df.page.apply(lambda x: x.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae67b1f-ef10-4cdb-9e28-230a43d47209",
   "metadata": {},
   "source": [
    "#### Creating chunk of 100 words each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb8ca3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_text = \"\"\n",
    "for page_num in range(len(pdf_reader.pages)):\n",
    "    page_text += (pdf_reader.pages[page_num].extract_text().lower())\n",
    "page_text = page_text.replace(\"\\n\",\"\")\n",
    "page_text = page_text.split(\" \")\n",
    "page_text = list(filter(None, page_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77cf9195-367a-4647-944b-3992967b9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "chunk_list = []\n",
    "while i < len(page_text):\n",
    "    chunk = \" \" \n",
    "    for i in range(i,i+100):\n",
    "        chunk += page_text[i]\n",
    "        chunk += \" \"\n",
    "    chunk_list.append(chunk)\n",
    "    i += 100\n",
    "page_text = chunk_list\n",
    "df = pd.DataFrame({\"page\":page_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "372616a1-7980-49b7-95f3-ed132553c54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ff34013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f1c550-e264-42cf-bcc6-7dc258da92cd",
   "metadata": {},
   "source": [
    "#### RAG using FAISS (creating embeddings and storing in vector index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e4632de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "558866a4-fc46-4ef0-91be-064501987862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 384)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\")\n",
    "faiss_embedding = model.encode(df.page.values.tolist())\n",
    "\n",
    "len(faiss_embedding),len(faiss_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "932a9524-87f4-4740-abb8-aa69c45dcb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fe1dc44-2cfc-4e56-97eb-25fa334477f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_to_index = df.set_index(['id'],drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66210a91-845b-4c45-a432-3cfe14714ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_index = np.array(pdf_to_index.id.values).flatten().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fb59562-fa7c-439e-ad17-fb0b11b1d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_encoded_normalized = faiss_embedding.copy()\n",
    "faiss.normalize_L2(content_encoded_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3c97081-960f-4a3a-af3d-a1b8614a745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_content = faiss.IndexIDMap(faiss.IndexFlatIP(len(faiss_embedding[0])))\n",
    "index_content.add_with_ids(content_encoded_normalized,id_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22f3f5-12e7-48c3-ac7c-297dc65b550e",
   "metadata": {},
   "source": [
    "##### Search function for Retrieval of nearest chunks/vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "64aa129b-b563-4a5e-bb01-115e2e49eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_context(query):\n",
    "    query_vector = model.encode([query])\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    \n",
    "    top_k = index_content.search(query_vector,3)\n",
    "    ids = top_k[1][0].tolist()\n",
    "    similarities = top_k[0][0].tolist()\n",
    "    results = pdf_to_index.loc[ids]\n",
    "    results['similarity'] = similarities\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a4f8b-2d5f-4f90-84bf-3c6b29c378c3",
   "metadata": {},
   "source": [
    "##### Defininig the query and fetching the required chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e3c2f05f-6a32-463c-bd0f-f263c65f17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Financial Performance of tesla\"\n",
    "query = \"Operation Efficiency of tesla\"\n",
    "\n",
    "res = search_context(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6ffc4a49-7f37-4ab6-84c0-790d3b65a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summarize = \" \"\n",
    "for item in res.page:\n",
    "    text_summarize += item\n",
    "    text_summarize += \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4697e-e730-4a60-9f55-8c9fc8621db8",
   "metadata": {},
   "source": [
    "##### Using retrieved chunks to generate the required summary using Hugging Face models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b903c215-da0b-4d61-b181-af781d7ca047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0af8eb42-6c2a-4189-9620-a0a04c2a09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir = \"\")\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f73238a1-3eca-4bcf-b5a0-162f26ca8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\", model = lm_model, tokenizer = tokenizer, max_new_tokens = 128, device_map = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fef31c04-faa2-4bb7-aab5-b9ef4eedbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"summarizing Tesla's financial performance\"\n",
    "question = \"summarizing Tesla's Operational Efficiency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0f773f73-aaa3-4838-86d5-09e1c3157916",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = f\"Relevant context: {text_summarize}\\n\\n The user's question: {question}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1a1ccbba-9944-4f0f-bbf9-cf188ee3649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant context:   and service operations to meet demand; competition and uncertainty regarding the future of electric vehicles or our other products and services; ourquarterly production and sales performance compared with market expectations; and other factors including those over which we have no control. in particular,teslaâ€™s products, business, results of operations, and statements and actions of tesla and its management are subject to significant amounts of commentary by arange of third parties. such attention can include criticism, which may be exaggerated or unfounded, such as speculation regarding the sufficiency or stabilityof our management team. any such negative perceptions, whether caused by us or   substantiallyincrease our production and installation capabilities. if we experience production delays or inaccurately forecast demand, our business, financial condition andoperating results may be harmed.moreover, because of our unique expertise with our vehicles, we recommend that our vehicles be serviced by us or by certain authorized professionals.if we experience delays in adding servicing capacity or servicing our vehicles efficiently, or experience unforeseen issues with the reliability of our vehicles,particularly higher-volume additions to our fleet such as model 3 and model y, it could overburden our servicing capabilities and parts inventory. similarly, theincreasing number of tesla vehicles also requires us to continue   i have reviewed this annual report on form 10-k of tesla, inc.;2. based on my knowledge, this report does not contain any untrue statement of a material fact or omit to state a material fact necessary to make thestatements made, in light of the circumstances under which such statements were made, not misleading with respect to the period covered by this report;3. based on my knowledge, the financial statements, and other financial information included in this report, fairly present in all material respects thefinancial condition, results of operations and cash flows of the registrant as of, and for, the periods  \n",
      "\n",
      " The user's question: summarizing Tesla's Operational Efficiency Statistics in this regard does not affect the accuracy or completeness of this report and other information that Tesla presents for the most part, which they believe is available to consumers or is derived from data collected in the fourth quarter, may be incomplete or incorrect. In addition, you are encouraged to review the reports Tesla presents for the most part and/or to verify that all facts are set forth in the forward-looking statements included in the Company's annual reports. thein this regard, You are encouraged to review the reports that Tesla presents for the most part and/or to verify that all facts are set forth in the Forward-looking Statements included\n"
     ]
    }
   ],
   "source": [
    "lm_response = pipe(prompt_template)\n",
    "print(lm_response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c9cbd3-8898-4f04-bdfb-8eea545efd6b",
   "metadata": {},
   "source": [
    "#### Results can be improved by exploring a better model (Chatgpt 4), redefining the chunk size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
